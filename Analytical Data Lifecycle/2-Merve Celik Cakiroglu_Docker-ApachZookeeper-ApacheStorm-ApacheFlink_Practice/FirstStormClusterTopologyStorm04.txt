2023-12-26 22:42:18.543 o.a.s.v.ConfigValidation main [INFO] Will use [class org.apache.storm.Config, class org.apache.storm.hdfs.spout.Configs] for validation
2023-12-26 22:42:18.662 o.a.s.d.w.LogConfigManager main [INFO] Started with log levels: {=INFO, STDERR=INFO, STDOUT=INFO, org.apache.storm.metric.LoggingMetricsConsumer=INFO}
2023-12-26 22:42:18.677 o.a.s.d.w.Worker main [INFO] Adding shutdown hook with kill in 3 secs
2023-12-26 22:42:21.061 o.a.s.d.w.Worker main [INFO] Launching worker for FirstStormClusterTopology-1-1703630456 on 02c58f36-6bc5-4837-95d5-a8f61f0d7d68:6700 with id e293af35-df7a-40df-9a19-3ba411ce1bfc and conf {storm.messaging.netty.min_wait_ms=100, topology.backpressure.wait.strategy=org.apache.storm.policy.WaitStrategyProgressive, storm.resource.isolation.plugin=org.apache.storm.container.cgroup.CgroupManager, storm.zookeeper.auth.user=null, storm.messaging.netty.buffer_size=5242880, storm.exhibitor.port=8080, topology.bolt.wait.progressive.level1.count=1, pacemaker.auth.method=NONE, storm.oci.cgroup.root=/sys/fs/cgroup, ui.filter=null, worker.profiler.enabled=false, executor.metrics.frequency.secs=60, supervisor.thrift.threads=16, ui.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, supervisor.supervisors.commands=[], supervisor.queue.size=128, logviewer.cleanup.age.mins=10080, topology.tuple.serializer=org.apache.storm.serialization.types.ListDelegateSerializer, storm.cgroup.memory.enforcement.enable=false, drpc.port=3772, supervisor.localizer.update.blob.interval.secs=30, topology.max.spout.pending=null, topology.transfer.buffer.size=1000, storm.oci.nscd.dir=/var/run/nscd, nimbus.worker.heartbeats.recovery.strategy.class=org.apache.storm.nimbus.TimeOutWorkerHeartbeatsRecoveryStrategy, worker.metrics={CGroupMemory=org.apache.storm.metrics2.cgroup.CGroupMemoryUsage, CGroupMemoryLimit=org.apache.storm.metrics2.cgroup.CGroupMemoryLimit, CGroupCpu=org.apache.storm.metrics2.cgroup.CGroupCpu, CGroupCpuGuarantee=org.apache.storm.metrics2.cgroup.CGroupCpuGuarantee, CGroupCpuGuaranteeByCfsQuota=org.apache.storm.metrics2.cgroup.CGroupCpuGuaranteeByCfsQuota, CGroupCpuStat=org.apache.storm.metrics2.cgroup.CGroupCpuStat}, logviewer.port=8000, worker.childopts=-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump, topology.component.cpu.pcore.percent=10.0, storm.daemon.metrics.reporter.plugins=[org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter], worker.max.timeout.secs=600, blacklist.scheduler.resume.time.secs=1800, drpc.childopts=-Xmx768m, nimbus.task.launch.secs=120, logviewer.childopts=-Xmx128m, topology.ras.acker.executors.per.worker=1, storm.supervisor.hard.memory.limit.overage.mb=2024, storm.zookeeper.servers=[zookeeper00, zookeeper01, zookeeper02], storm.messaging.transport=org.apache.storm.messaging.netty.Context, storm.messaging.netty.authentication=false, topology.localityaware.higher.bound=0.8, storm.cgroup.memory.limit.tolerance.margin.mb=0.0, storm.cgroup.hierarchy.name=storm, blacklist.scheduler.assume.supervisor.bad.based.on.bad.slot=true, storm.metricprocessor.class=org.apache.storm.metricstore.NimbusMetricProcessor, topology.kryo.factory=org.apache.storm.serialization.DefaultKryoFactory, nimbus.assignments.service.threads=10, worker.heap.memory.mb=768, storm.network.topography.plugin=org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping, supervisor.slots.ports=[6700, 6701, 6702, 6703], topology.stats.sample.rate=0.05, storm.local.dir=/tmp/storm-data, topology.backpressure.wait.park.microsec=100, topology.ras.constraint.max.state.search=10000, storm.oci.cgroup.parent=/storm, topology.testing.always.try.serialize=false, nimbus.assignments.service.thread.queue.size=100, storm.principal.tolocal=org.apache.storm.security.auth.DefaultPrincipalToLocal, java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib:/usr/lib64, nimbus.local.assignments.backend.class=org.apache.storm.assignments.InMemoryAssignmentBackend, worker.gc.childopts=, storm.group.mapping.service.cache.duration.secs=120, topology.multilang.serializer=org.apache.storm.multilang.JsonSerializer, drpc.request.timeout.secs=600, nimbus.blobstore.class=org.apache.storm.blobstore.LocalFsBlobStore, topology.state.synchronization.timeout.secs=60, topology.bolt.wait.progressive.level2.count=1000, topology.worker.shared.thread.pool.size=4, topology.executor.receive.buffer.size=32768, pacemaker.servers=[], supervisor.monitor.frequency.secs=3, storm.nimbus.retry.times=5, topology.transfer.batch.size=1, transactional.zookeeper.port=null, storm.auth.simple-white-list.users=[], topology.scheduler.strategy=org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy, storm.zookeeper.port=2181, storm.zookeeper.retry.intervalceiling.millis=30000, storm.cluster.state.store=org.apache.storm.cluster.ZKStateStorageFactory, nimbus.thrift.port=6627, blacklist.scheduler.tolerance.count=3, nimbus.thrift.threads=64, supervisor.supervisors=[], nimbus.seeds=[storm00, storm01], storm.cluster.metrics.consumer.publish.interval.secs=60, logviewer.filter.params=null, topology.min.replication.count=1, nimbus.blobstore.expiration.secs=600, storm.group.mapping.service=org.apache.storm.security.auth.ShellBasedGroupsMapping, storm.nimbus.retry.interval.millis=2000, topology.max.task.parallelism=null, topology.backpressure.wait.progressive.level2.count=1000, drpc.https.keystore.password=, resource.aware.scheduler.constraint.max.state.search=100000, supervisor.heartbeat.frequency.secs=5, nimbus.credential.renewers.freq.secs=600, storm.supervisor.medium.memory.grace.period.ms=30000, storm.thrift.transport=org.apache.storm.security.auth.SimpleTransportPlugin, storm.cgroup.hierarchy.dir=/cgroup/storm_resources, storm.zookeeper.auth.password=null, ui.port=8080, drpc.authorizer.acl.strict=false, topology.message.timeout.secs=30, topology.error.throttle.interval.secs=10, topology.backpressure.check.millis=50, drpc.https.keystore.type=JKS, supervisor.memory.capacity.mb=4096.0, storm.metricstore.class=org.apache.storm.metricstore.rocksdb.RocksDbStore, drpc.authorizer.acl.filename=drpc-auth-acl.yaml, topology.builtin.metrics.bucket.size.secs=60, topology.spout.wait.park.microsec=100, storm.local.mode.zmq=false, pacemaker.client.max.threads=2, ui.header.buffer.bytes=4096, topology.shellbolt.max.pending=100, topology.serialized.message.size.metrics=false, drpc.max_buffer_size=1048576, drpc.disable.http.binding=true, storm.codedistributor.class=org.apache.storm.codedistributor.LocalFileSystemCodeDistributor, worker.profiler.childopts=-XX:+UnlockCommercialFeatures -XX:+FlightRecorder, nimbus.supervisor.timeout.secs=60, storm.supervisor.cgroup.rootdir=storm, topology.worker.max.heap.size.mb=768.0, storm.zookeeper.root=/storm, topology.disable.loadaware.messaging=false, topology.ras.one.executor.per.worker=false, storm.supervisor.hard.memory.limit.multiplier=2.0, nimbus.topology.validator=org.apache.storm.nimbus.DefaultTopologyValidator, worker.heartbeat.frequency.secs=1, storm.messaging.netty.max_wait_ms=1000, topology.backpressure.wait.progressive.level1.count=1, topology.max.error.report.per.interval=5, nimbus.thrift.max_buffer_size=1048576, storm.metricstore.rocksdb.location=storm_rocks, storm.supervisor.low.memory.threshold.mb=1024, pacemaker.max.threads=50, ui.pagination=20, ui.disable.http.binding=true, supervisor.blobstore.download.max_retries=3, topology.enable.message.timeouts=true, logviewer.disable.http.binding=true, storm.messaging.netty.transfer.batch.size=262144, topology.spout.wait.progressive.level2.count=0, blacklist.scheduler.strategy=org.apache.storm.scheduler.blacklist.strategies.DefaultBlacklistStrategy, storm.metricstore.rocksdb.retention_hours=240, supervisor.run.worker.as.user=false, storm.messaging.netty.client_worker_threads=1, topology.tasks=null, supervisor.thrift.socket.timeout.ms=5000, storm.group.mapping.service.params=null, drpc.http.port=3774, transactional.zookeeper.root=/transactional, supervisor.blobstore.download.thread.count=5, logviewer.filter=null, pacemaker.kerberos.users=[], topology.spout.wait.strategy=org.apache.storm.policy.WaitStrategyProgressive, storm.blobstore.inputstream.buffer.size.bytes=65536, supervisor.worker.heartbeats.max.timeout.secs=600, supervisor.worker.timeout.secs=30, topology.worker.receiver.thread.count=1, logviewer.max.sum.worker.logs.size.mb=4096, topology.executor.overflow.limit=0, topology.batch.flush.interval.millis=1, nimbus.file.copy.expiration.secs=600, pacemaker.port=6699, topology.worker.logwriter.childopts=-Xmx64m, drpc.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, nimbus.topology.blobstore.deletion.delay.ms=300000, storm.blobstore.acl.validation.enabled=false, ui.filter.params=null, topology.workers=1, blacklist.scheduler.tolerance.time.secs=300, storm.supervisor.medium.memory.threshold.mb=1536, topology.environment=null, drpc.invocations.port=3773, storm.metricstore.rocksdb.create_if_missing=true, nimbus.cleanup.inbox.freq.secs=600, client.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, topology.fall.back.on.java.serialization=false, storm.nimbus.retry.intervalceiling.millis=60000, storm.nimbus.zookeeper.acls.fixup=true, logviewer.appender.name=A1, ui.users=null, pacemaker.childopts=-Xmx1024m, storm.messaging.netty.server_worker_threads=1, scheduler.display.resource=false, ui.actions.enabled=true, storm.thrift.socket.timeout.ms=600000, storm.topology.classpath.beginning.enabled=false, storm.zookeeper.connection.timeout=15000, topology.tick.tuple.freq.secs=null, nimbus.inbox.jar.expiration.secs=3600, topology.debug=false, storm.zookeeper.retry.interval=1000, storm.messaging.netty.buffer.high.watermark=16777216, storm.blobstore.dependency.jar.upload.chunk.size.bytes=1048576, worker.log.level.reset.poll.secs=30, storm.exhibitor.poll.uripath=/exhibitor/v1/cluster/list, storm.zookeeper.retry.times=5, nimbus.code.sync.freq.secs=120, topology.component.resources.offheap.memory.mb=0.0, topology.spout.wait.progressive.level1.count=0, topology.state.checkpoint.interval.ms=1000, topology.priority=29, supervisor.localizer.cleanup.interval.ms=30000, storm.health.check.dir=healthchecks, supervisor.cpu.capacity=400.0, topology.backpressure.wait.progressive.level3.sleep.millis=1, storm.cgroup.resources=[cpu, memory], storm.worker.min.cpu.pcore.percent=0.0, topology.classpath=null, storm.nimbus.zookeeper.acls.check=true, num.stat.buckets=20, topology.spout.wait.progressive.level3.sleep.millis=1, supervisor.localizer.cache.target.size.mb=10240, topology.worker.childopts=null, drpc.https.port=-1, topology.bolt.wait.park.microsec=100, topology.max.replication.wait.time.sec=60, storm.cgroup.cgexec.cmd=/bin/cgexec, topology.acker.executors=null, topology.bolt.wait.progressive.level3.sleep.millis=1, supervisor.worker.start.timeout.secs=120, supervisor.worker.shutdown.sleep.secs=3, logviewer.max.per.worker.logs.size.mb=2048, topology.trident.batch.emit.interval.millis=500, task.heartbeat.frequency.secs=3, supervisor.enable=true, supervisor.thrift.max_buffer_size=1048576, supervisor.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, topology.producer.batch.size=1, drpc.worker.threads=64, resource.aware.scheduler.priority.strategy=org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy, blacklist.scheduler.reporter=org.apache.storm.scheduler.blacklist.reporters.LogReporter, storm.messaging.netty.socket.backlog=500, storm.cgroup.inherit.cpuset.configs=false, nimbus.queue.size=100000, drpc.queue.size=128, ui.disable.spout.lag.monitoring=true, topology.eventlogger.executors=0, pacemaker.base.threads=10, nimbus.childopts=-Xmx1024m, topology.spout.recvq.skips=3, storm.resource.isolation.plugin.enable=false, nimbus.monitor.freq.secs=10, storm.supervisor.memory.limit.tolerance.margin.mb=128.0, storm.disable.symlinks=false, topology.localityaware.lower.bound=0.2, transactional.zookeeper.servers=null, nimbus.task.timeout.secs=30, logs.users=null, pacemaker.thrift.message.size.max=10485760, topology.ras.one.component.per.worker=false, ui.host=0.0.0.0, supervisor.thrift.port=6628, topology.bolt.wait.strategy=org.apache.storm.policy.WaitStrategyProgressive, pacemaker.thread.timeout=10, storm.meta.serialization.delegate=org.apache.storm.serialization.GzipThriftSerializationDelegate, dev.zookeeper.path=/tmp/dev-storm-zookeeper, topology.skip.missing.kryo.registrations=false, drpc.invocations.threads=64, storm.zookeeper.session.timeout=20000, storm.metricstore.rocksdb.metadata_string_cache_capacity=4000, storm.workers.artifacts.dir=workers-artifacts, topology.component.resources.onheap.memory.mb=128.0, storm.log4j2.conf.dir=log4j2, storm.cluster.mode=distributed, ui.childopts=-Xmx768m, task.refresh.poll.secs=10, supervisor.childopts=-Xmx256m, task.credentials.poll.secs=30, storm.health.check.timeout.ms=5000, storm.blobstore.replication.factor=3, worker.profiler.command=flight.bash, storm.messaging.netty.buffer.low.watermark=8388608}
2023-12-26 22:42:21.069 o.a.s.s.u.o.l.s.c.SysOutOverSLF4JInitialiser main [WARN] Your logging framework class org.apache.logging.slf4j.Log4jLogger is not known - if it needs access to the standard println methods on the console you will need to register it by calling registerLoggingSystemPackage
2023-12-26 22:42:21.073 o.a.s.s.u.o.l.s.c.SysOutOverSLF4J main [INFO] Replaced standard System.out and System.err PrintStreams with SLF4JPrintStreams
2023-12-26 22:42:21.074 o.a.s.s.u.o.l.s.c.SysOutOverSLF4J main [INFO] Redirected System.out and System.err to SLF4J for this context
2023-12-26 22:42:21.132 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT
2023-12-26 22:42:21.132 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:host.name=storm04
2023-12-26 22:42:21.132 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.version=1.8.0_181
2023-12-26 22:42:21.132 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.vendor=Oracle Corporation
2023-12-26 22:42:21.132 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.home=/usr/java/jdk1.8.0_181-amd64/jre
2023-12-26 22:42:21.133 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.class.path=/opt/apache-storm-2.4.0/lib-worker/jakarta.xml.bind-api-2.3.2.jar:/opt/apache-storm-2.4.0/lib-worker/minlog-1.3.0.jar:/opt/apache-storm-2.4.0/lib-worker/slf4j-api-1.7.36.jar:/opt/apache-storm-2.4.0/lib-worker/metrics-graphite-3.2.6.jar:/opt/apache-storm-2.4.0/lib-worker/javax.annotation-api-1.3.2.jar:/opt/apache-storm-2.4.0/lib-worker/log4j-api-2.17.1.jar:/opt/apache-storm-2.4.0/lib-worker/kryo-3.0.3.jar:/opt/apache-storm-2.4.0/lib-worker/log4j-core-2.17.1.jar:/opt/apache-storm-2.4.0/lib-worker/objenesis-2.1.jar:/opt/apache-storm-2.4.0/lib-worker/log4j-slf4j-impl-2.17.1.jar:/opt/apache-storm-2.4.0/lib-worker/jakarta.activation-1.2.1.jar:/opt/apache-storm-2.4.0/lib-worker/log4j-over-slf4j-1.7.36.jar:/opt/apache-storm-2.4.0/lib-worker/jakarta.activation-api-1.2.1.jar:/opt/apache-storm-2.4.0/lib-worker/metrics-core-3.2.6.jar:/opt/apache-storm-2.4.0/lib-worker/metrics-jvm-3.2.6.jar:/opt/apache-storm-2.4.0/lib-worker/asm-5.0.3.jar:/opt/apache-storm-2.4.0/lib-worker/reflectasm-1.10.1.jar:/opt/apache-storm-2.4.0/lib-worker/storm-shaded-deps-2.4.0.jar:/opt/apache-storm-2.4.0/lib-worker/storm-client-2.4.0.jar:/opt/apache-storm-2.4.0/extlib/*:/opt/apache-storm-2.4.0/conf:/tmp/storm-data/supervisor/stormdist/FirstStormClusterTopology-1-1703630456/stormjar.jar
2023-12-26 22:42:21.133 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.library.path=/tmp/storm-data/supervisor/stormdist/FirstStormClusterTopology-1-1703630456/resources/Linux-amd64:/tmp/storm-data/supervisor/stormdist/FirstStormClusterTopology-1-1703630456/resources:/usr/local/lib:/opt/local/lib:/usr/lib:/usr/lib64
2023-12-26 22:42:21.133 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.io.tmpdir=/tmp/storm-data/workers/e293af35-df7a-40df-9a19-3ba411ce1bfc/tmp
2023-12-26 22:42:21.133 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.compiler=<NA>
2023-12-26 22:42:21.133 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.name=Linux
2023-12-26 22:42:21.133 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.arch=amd64
2023-12-26 22:42:21.133 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.version=3.10.0-862.el7.x86_64
2023-12-26 22:42:21.133 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:user.name=root
2023-12-26 22:42:21.133 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:user.home=/root
2023-12-26 22:42:21.133 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:user.dir=/tmp/storm-data/workers/e293af35-df7a-40df-9a19-3ba411ce1bfc
2023-12-26 22:42:21.133 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.memory.free=85MB
2023-12-26 22:42:21.133 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.memory.max=341MB
2023-12-26 22:42:21.133 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.memory.total=119MB
2023-12-26 22:42:21.134 o.a.s.s.o.a.c.u.Compatibility main [INFO] Using emulated InjectSessionExpiration
2023-12-26 22:42:21.165 o.a.s.z.ClientZookeeper main [INFO] Starting ZK Curator
2023-12-26 22:42:21.165 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Starting
2023-12-26 22:42:21.168 o.a.s.s.o.a.z.ZooKeeper main [INFO] Initiating client connection, connectString=zookeeper00:2181,zookeeper01:2181,zookeeper02:2181 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@1cdc4c27
2023-12-26 22:42:21.179 o.a.s.s.o.a.z.c.X509Util main [INFO] Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
2023-12-26 22:42:21.182 o.a.s.s.o.a.z.ClientCnxnSocket main [INFO] jute.maxbuffer value is 4194304 Bytes
2023-12-26 22:42:21.197 o.a.s.s.o.a.z.ClientCnxn main [INFO] zookeeper.request.timeout value is 0. feature enabled=
2023-12-26 22:42:21.205 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Default schema
2023-12-26 22:42:21.221 o.a.s.s.o.a.z.ClientCnxn main-SendThread(zookeeper02:2181) [INFO] Opening socket connection to server zookeeper02/192.168.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
2023-12-26 22:42:21.234 o.a.s.s.o.a.z.ClientCnxn main-SendThread(zookeeper02:2181) [INFO] Socket connection established, initiating session, client: /192.168.0.9:60696, server: zookeeper02/192.168.0.4:2181
2023-12-26 22:42:21.240 o.a.s.s.o.a.z.ClientCnxn main-SendThread(zookeeper02:2181) [INFO] Session establishment complete on server zookeeper02/192.168.0.4:2181, sessionid = 0x20000666f2a0000, negotiated timeout = 20000
2023-12-26 22:42:21.244 o.a.s.s.o.a.c.f.s.ConnectionStateManager main-EventThread [INFO] State change: CONNECTED
2023-12-26 22:42:22.493 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {server.1=zookeeper01:2888:3888:participant, version=0, server.0=zookeeper00:2888:3888:participant, server.2=zookeeper02:2888:3888:participant}
2023-12-26 22:42:22.668 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl Curator-Framework-0 [INFO] backgroundOperationsLoop exiting
2023-12-26 22:42:22.679 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [ERROR] Invalid config event received: {server.1=zookeeper01:2888:3888:participant, version=0, server.0=zookeeper00:2888:3888:participant, server.2=zookeeper02:2888:3888:participant}
2023-12-26 22:42:22.679 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {server.1=zookeeper01:2888:3888:participant, version=0, server.0=zookeeper00:2888:3888:participant, server.2=zookeeper02:2888:3888:participant}
2023-12-26 22:42:22.680 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [ERROR] Invalid config event received: {server.1=zookeeper01:2888:3888:participant, version=0, server.0=zookeeper00:2888:3888:participant, server.2=zookeeper02:2888:3888:participant}
2023-12-26 22:42:23.899 o.a.s.s.o.a.z.ClientCnxn main-EventThread [INFO] EventThread shut down for session: 0x20000666f2a0000
2023-12-26 22:42:23.899 o.a.s.s.o.a.z.ZooKeeper main [INFO] Session: 0x20000666f2a0000 closed
2023-12-26 22:42:24.556 o.a.s.z.ClientZookeeper main [INFO] Starting ZK Curator
2023-12-26 22:42:24.606 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Starting
2023-12-26 22:42:24.608 o.a.s.s.o.a.z.ZooKeeper main [INFO] Initiating client connection, connectString=zookeeper00:2181,zookeeper01:2181,zookeeper02:2181/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@4c5474f5
2023-12-26 22:42:24.777 o.a.s.s.o.a.z.ClientCnxnSocket main [INFO] jute.maxbuffer value is 4194304 Bytes
2023-12-26 22:42:25.030 o.a.s.s.o.a.z.ClientCnxn main [INFO] zookeeper.request.timeout value is 0. feature enabled=
2023-12-26 22:42:25.171 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Default schema
2023-12-26 22:42:25.179 o.a.s.s.o.a.z.ClientCnxn main-SendThread(zookeeper01:2181) [INFO] Opening socket connection to server zookeeper01/192.168.0.3:2181. Will not attempt to authenticate using SASL (unknown error)
2023-12-26 22:42:25.179 o.a.s.s.o.a.z.ClientCnxn main-SendThread(zookeeper01:2181) [INFO] Socket connection established, initiating session, client: /192.168.0.9:56698, server: zookeeper01/192.168.0.3:2181
2023-12-26 22:42:25.197 o.a.s.s.o.a.z.ClientCnxn main-SendThread(zookeeper01:2181) [INFO] Session establishment complete on server zookeeper01/192.168.0.3:2181, sessionid = 0x1000066708f0001, negotiated timeout = 20000
2023-12-26 22:42:25.197 o.a.s.s.o.a.c.f.s.ConnectionStateManager main-EventThread [INFO] State change: CONNECTED
2023-12-26 22:42:25.200 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {server.1=zookeeper01:2888:3888:participant, version=0, server.0=zookeeper00:2888:3888:participant, server.2=zookeeper02:2888:3888:participant}
2023-12-26 22:42:25.200 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [ERROR] Invalid config event received: {server.1=zookeeper01:2888:3888:participant, version=0, server.0=zookeeper00:2888:3888:participant, server.2=zookeeper02:2888:3888:participant}
2023-12-26 22:42:25.201 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {server.1=zookeeper01:2888:3888:participant, version=0, server.0=zookeeper00:2888:3888:participant, server.2=zookeeper02:2888:3888:participant}
2023-12-26 22:42:25.202 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [ERROR] Invalid config event received: {server.1=zookeeper01:2888:3888:participant, version=0, server.0=zookeeper00:2888:3888:participant, server.2=zookeeper02:2888:3888:participant}
2023-12-26 22:42:25.253 o.a.s.m.StormMetricRegistry main [INFO] Starting metrics reporters...
2023-12-26 22:42:25.260 o.a.s.s.a.ClientAuthUtils main [INFO] Got AutoCreds []
2023-12-26 22:42:25.403 o.a.s.m.TransportFactory main [INFO] Storm peer transport plugin:org.apache.storm.messaging.netty.Context
2023-12-26 22:42:35.133 o.a.s.d.w.WorkerState main [INFO] Registering IConnectionCallbacks for 02c58f36-6bc5-4837-95d5-a8f61f0d7d68:6700
2023-12-26 22:42:43.538 o.a.s.m.n.Server main [INFO] Create Netty Server Netty-server-localhost-6700, buffer_size: 5242880, maxWorkers: 1
2023-12-26 22:42:43.731 o.a.s.m.n.Client main [INFO] Creating Netty Client, connecting to storm03:6700, bufferSize: 5242880, lowWatermark: 8388608, highWatermark: 16777216
2023-12-26 22:42:43.745 o.a.s.m.n.Client main [INFO] Creating Netty Client, connecting to storm02:6700, bufferSize: 5242880, lowWatermark: 8388608, highWatermark: 16777216
2023-12-26 22:42:45.163 o.a.s.m.n.Client client-worker-1 [ERROR] connection attempt 1 to Netty-Client-storm03/192.168.0.8:6700 failed: org.apache.storm.shade.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: storm03/192.168.0.8:6700
2023-12-26 22:42:45.164 o.a.s.m.n.Client client-worker-1 [ERROR] connection attempt 1 to Netty-Client-storm02/192.168.0.7:6700 failed: org.apache.storm.shade.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: storm02/192.168.0.7:6700
2023-12-26 22:42:45.393 o.a.s.m.n.Client client-worker-1 [ERROR] connection attempt 2 to Netty-Client-storm02/192.168.0.7:6700 failed: org.apache.storm.shade.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: storm02/192.168.0.7:6700
2023-12-26 22:42:45.475 o.a.s.e.Executor main [INFO] Loading executor tasks __system:[-1, -1]
2023-12-26 22:42:45.523 o.a.s.e.Executor main [INFO] Finished loading executor __system:[-1, -1]
2023-12-26 22:42:45.555 o.a.s.e.Executor main [INFO] Loading executor tasks FirstBolt:[4, 4]
2023-12-26 22:42:46.343 o.a.s.e.Executor main [INFO] Finished loading executor FirstBolt:[4, 4]
2023-12-26 22:42:46.344 o.a.s.e.Executor main [INFO] Loading executor tasks __acker:[7, 7]
2023-12-26 22:42:46.681 o.a.s.e.Executor main [INFO] Finished loading executor __acker:[7, 7]
2023-12-26 22:42:46.684 o.a.s.e.Executor main [INFO] Loading executor tasks FirstBolt:[1, 1]
2023-12-26 22:42:46.687 o.a.s.e.Executor main [INFO] Finished loading executor FirstBolt:[1, 1]
2023-12-26 22:42:46.699 o.a.s.d.w.Worker main [INFO] Flush Tuple generation disabled. producerBatchSize=1, xferBatchSize=1, flushIntervalMillis=1
2023-12-26 22:42:46.699 o.a.s.d.w.Worker main [INFO] BackPressure status change checking will be performed every 50 millis
2023-12-26 22:42:46.700 o.a.s.d.w.Worker main [INFO] Worker has topology config {storm.messaging.netty.min_wait_ms=100, topology.backpressure.wait.strategy=org.apache.storm.policy.WaitStrategyProgressive, topology.submitter.principal=, storm.resource.isolation.plugin=org.apache.storm.container.cgroup.CgroupManager, storm.zookeeper.auth.user=null, storm.messaging.netty.buffer_size=5242880, topology.name=FirstStormClusterTopology, storm.exhibitor.port=8080, topology.bolt.wait.progressive.level1.count=1, pacemaker.auth.method=NONE, storm.oci.cgroup.root=/sys/fs/cgroup, ui.filter=null, worker.profiler.enabled=false, executor.metrics.frequency.secs=60, storm.id=FirstStormClusterTopology-1-1703630456, supervisor.thrift.threads=16, ui.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, supervisor.supervisors.commands=[], supervisor.queue.size=128, logviewer.cleanup.age.mins=10080, topology.tuple.serializer=org.apache.storm.serialization.types.ListDelegateSerializer, storm.cgroup.memory.enforcement.enable=false, drpc.port=3772, supervisor.localizer.update.blob.interval.secs=30, topology.max.spout.pending=null, topology.transfer.buffer.size=1000, storm.oci.nscd.dir=/var/run/nscd, nimbus.worker.heartbeats.recovery.strategy.class=org.apache.storm.nimbus.TimeOutWorkerHeartbeatsRecoveryStrategy, worker.metrics={CGroupCpuStat=org.apache.storm.metrics2.cgroup.CGroupCpuStat, CGroupMemoryLimit=org.apache.storm.metrics2.cgroup.CGroupMemoryLimit, CGroupCpuGuaranteeByCfsQuota=org.apache.storm.metrics2.cgroup.CGroupCpuGuaranteeByCfsQuota, CGroupMemory=org.apache.storm.metrics2.cgroup.CGroupMemoryUsage, CGroupCpu=org.apache.storm.metrics2.cgroup.CGroupCpu, CGroupCpuGuarantee=org.apache.storm.metrics2.cgroup.CGroupCpuGuarantee}, logviewer.port=8000, worker.childopts=-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump, topology.component.cpu.pcore.percent=10.0, storm.daemon.metrics.reporter.plugins=[org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter], worker.max.timeout.secs=600, blacklist.scheduler.resume.time.secs=1800, drpc.childopts=-Xmx768m, nimbus.task.launch.secs=120, logviewer.childopts=-Xmx128m, topology.ras.acker.executors.per.worker=1, storm.supervisor.hard.memory.limit.overage.mb=2024, storm.zookeeper.servers=[zookeeper00, zookeeper01, zookeeper02], storm.messaging.transport=org.apache.storm.messaging.netty.Context, storm.messaging.netty.authentication=false, topology.localityaware.higher.bound=0.8, storm.cgroup.memory.limit.tolerance.margin.mb=0.0, storm.cgroup.hierarchy.name=storm, blacklist.scheduler.assume.supervisor.bad.based.on.bad.slot=true, storm.metricprocessor.class=org.apache.storm.metricstore.NimbusMetricProcessor, topology.kryo.factory=org.apache.storm.serialization.DefaultKryoFactory, nimbus.assignments.service.threads=10, worker.heap.memory.mb=768, storm.network.topography.plugin=org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping, supervisor.slots.ports=[6700, 6701, 6702, 6703], topology.stats.sample.rate=0.05, storm.local.dir=/tmp/storm-data, topology.backpressure.wait.park.microsec=100, topology.ras.constraint.max.state.search=10000, storm.oci.cgroup.parent=/storm, topology.testing.always.try.serialize=false, nimbus.assignments.service.thread.queue.size=100, storm.principal.tolocal=org.apache.storm.security.auth.DefaultPrincipalToLocal, java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib:/usr/lib64, nimbus.local.assignments.backend.class=org.apache.storm.assignments.InMemoryAssignmentBackend, worker.gc.childopts=, storm.group.mapping.service.cache.duration.secs=120, topology.multilang.serializer=org.apache.storm.multilang.JsonSerializer, topology.kryo.register={}, drpc.request.timeout.secs=600, nimbus.blobstore.class=org.apache.storm.blobstore.LocalFsBlobStore, topology.state.synchronization.timeout.secs=60, topology.bolt.wait.progressive.level2.count=1000, topology.kryo.decorators=[], topology.worker.shared.thread.pool.size=4, topology.submitter.user=root, topology.executor.receive.buffer.size=32768, pacemaker.servers=[], supervisor.monitor.frequency.secs=3, storm.nimbus.retry.times=5, topology.transfer.batch.size=1, transactional.zookeeper.port=null, storm.auth.simple-white-list.users=[], topology.scheduler.strategy=org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy, storm.zookeeper.port=2181, storm.zookeeper.retry.intervalceiling.millis=30000, storm.cluster.state.store=org.apache.storm.cluster.ZKStateStorageFactory, nimbus.thrift.port=6627, blacklist.scheduler.tolerance.count=3, nimbus.thrift.threads=64, supervisor.supervisors=[], nimbus.seeds=[storm00, storm01], storm.cluster.metrics.consumer.publish.interval.secs=60, logviewer.filter.params=null, topology.min.replication.count=1, nimbus.blobstore.expiration.secs=600, storm.group.mapping.service=org.apache.storm.security.auth.ShellBasedGroupsMapping, storm.nimbus.retry.interval.millis=2000, topology.max.task.parallelism=null, topology.backpressure.wait.progressive.level2.count=1000, drpc.https.keystore.password=, resource.aware.scheduler.constraint.max.state.search=100000, supervisor.heartbeat.frequency.secs=5, nimbus.credential.renewers.freq.secs=600, storm.supervisor.medium.memory.grace.period.ms=30000, storm.thrift.transport=org.apache.storm.security.auth.SimpleTransportPlugin, storm.cgroup.hierarchy.dir=/cgroup/storm_resources, storm.zookeeper.auth.password=null, ui.port=8080, drpc.authorizer.acl.strict=false, topology.message.timeout.secs=30, topology.error.throttle.interval.secs=10, topology.backpressure.check.millis=50, drpc.https.keystore.type=JKS, supervisor.memory.capacity.mb=4096.0, storm.metricstore.class=org.apache.storm.metricstore.rocksdb.RocksDbStore, drpc.authorizer.acl.filename=drpc-auth-acl.yaml, topology.builtin.metrics.bucket.size.secs=60, topology.spout.wait.park.microsec=100, storm.local.mode.zmq=false, pacemaker.client.max.threads=2, ui.header.buffer.bytes=4096, topology.shellbolt.max.pending=100, topology.serialized.message.size.metrics=false, drpc.max_buffer_size=1048576, drpc.disable.http.binding=true, storm.codedistributor.class=org.apache.storm.codedistributor.LocalFileSystemCodeDistributor, worker.profiler.childopts=-XX:+UnlockCommercialFeatures -XX:+FlightRecorder, nimbus.supervisor.timeout.secs=60, storm.supervisor.cgroup.rootdir=storm, topology.worker.max.heap.size.mb=768.0, storm.zookeeper.root=/storm, topology.disable.loadaware.messaging=false, topology.ras.one.executor.per.worker=false, storm.supervisor.hard.memory.limit.multiplier=2.0, nimbus.topology.validator=org.apache.storm.nimbus.DefaultTopologyValidator, worker.heartbeat.frequency.secs=1, storm.messaging.netty.max_wait_ms=1000, topology.backpressure.wait.progressive.level1.count=1, topology.max.error.report.per.interval=5, nimbus.thrift.max_buffer_size=1048576, storm.metricstore.rocksdb.location=storm_rocks, storm.supervisor.low.memory.threshold.mb=1024, pacemaker.max.threads=50, ui.pagination=20, ui.disable.http.binding=true, supervisor.blobstore.download.max_retries=3, topology.enable.message.timeouts=true, logviewer.disable.http.binding=true, storm.messaging.netty.transfer.batch.size=262144, topology.spout.wait.progressive.level2.count=0, blacklist.scheduler.strategy=org.apache.storm.scheduler.blacklist.strategies.DefaultBlacklistStrategy, storm.metricstore.rocksdb.retention_hours=240, supervisor.run.worker.as.user=false, storm.messaging.netty.client_worker_threads=1, topology.tasks=null, supervisor.thrift.socket.timeout.ms=5000, storm.group.mapping.service.params=null, drpc.http.port=3774, transactional.zookeeper.root=/transactional, supervisor.blobstore.download.thread.count=5, logviewer.filter=null, pacemaker.kerberos.users=[], topology.spout.wait.strategy=org.apache.storm.policy.WaitStrategyProgressive, storm.blobstore.inputstream.buffer.size.bytes=65536, supervisor.worker.heartbeats.max.timeout.secs=600, supervisor.worker.timeout.secs=30, topology.worker.receiver.thread.count=1, logviewer.max.sum.worker.logs.size.mb=4096, topology.executor.overflow.limit=0, topology.batch.flush.interval.millis=1, nimbus.file.copy.expiration.secs=600, pacemaker.port=6699, topology.worker.logwriter.childopts=-Xmx64m, drpc.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, nimbus.topology.blobstore.deletion.delay.ms=300000, storm.blobstore.acl.validation.enabled=false, ui.filter.params=null, topology.workers=3, blacklist.scheduler.tolerance.time.secs=300, storm.supervisor.medium.memory.threshold.mb=1536, topology.environment=null, drpc.invocations.port=3773, storm.metricstore.rocksdb.create_if_missing=true, nimbus.cleanup.inbox.freq.secs=600, client.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, topology.fall.back.on.java.serialization=false, storm.nimbus.retry.intervalceiling.millis=60000, storm.nimbus.zookeeper.acls.fixup=true, logviewer.appender.name=A1, ui.users=null, pacemaker.childopts=-Xmx1024m, storm.messaging.netty.server_worker_threads=1, scheduler.display.resource=false, ui.actions.enabled=true, storm.thrift.socket.timeout.ms=600000, storm.topology.classpath.beginning.enabled=false, storm.zookeeper.connection.timeout=15000, topology.tick.tuple.freq.secs=null, nimbus.inbox.jar.expiration.secs=3600, topology.debug=false, storm.zookeeper.retry.interval=1000, storm.messaging.netty.buffer.high.watermark=16777216, storm.blobstore.dependency.jar.upload.chunk.size.bytes=1048576, worker.log.level.reset.poll.secs=30, storm.exhibitor.poll.uripath=/exhibitor/v1/cluster/list, storm.zookeeper.retry.times=5, nimbus.code.sync.freq.secs=120, topology.component.resources.offheap.memory.mb=0.0, topology.spout.wait.progressive.level1.count=0, topology.state.checkpoint.interval.ms=1000, topology.priority=29, supervisor.localizer.cleanup.interval.ms=30000, storm.health.check.dir=healthchecks, supervisor.cpu.capacity=400.0, topology.backpressure.wait.progressive.level3.sleep.millis=1, storm.cgroup.resources=[cpu, memory], storm.worker.min.cpu.pcore.percent=0.0, topology.classpath=null, storm.nimbus.zookeeper.acls.check=true, num.stat.buckets=20, topology.spout.wait.progressive.level3.sleep.millis=1, supervisor.localizer.cache.target.size.mb=10240, topology.worker.childopts=null, drpc.https.port=-1, topology.bolt.wait.park.microsec=100, topology.max.replication.wait.time.sec=60, storm.cgroup.cgexec.cmd=/bin/cgexec, topology.users=[null], topology.acker.executors=null, topology.bolt.wait.progressive.level3.sleep.millis=1, supervisor.worker.start.timeout.secs=120, supervisor.worker.shutdown.sleep.secs=3, logviewer.max.per.worker.logs.size.mb=2048, topology.trident.batch.emit.interval.millis=500, task.heartbeat.frequency.secs=3, supervisor.enable=true, supervisor.thrift.max_buffer_size=1048576, supervisor.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, topology.producer.batch.size=1, drpc.worker.threads=64, resource.aware.scheduler.priority.strategy=org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy, blacklist.scheduler.reporter=org.apache.storm.scheduler.blacklist.reporters.LogReporter, storm.messaging.netty.socket.backlog=500, storm.cgroup.inherit.cpuset.configs=false, nimbus.queue.size=100000, drpc.queue.size=128, ui.disable.spout.lag.monitoring=true, topology.eventlogger.executors=0, pacemaker.base.threads=10, nimbus.childopts=-Xmx1024m, topology.spout.recvq.skips=3, storm.zookeeper.superACL=null, storm.resource.isolation.plugin.enable=false, nimbus.monitor.freq.secs=10, storm.supervisor.memory.limit.tolerance.margin.mb=128.0, storm.disable.symlinks=false, topology.localityaware.lower.bound=0.2, transactional.zookeeper.servers=null, nimbus.task.timeout.secs=30, logs.users=null, pacemaker.thrift.message.size.max=10485760, topology.ras.one.component.per.worker=false, ui.host=0.0.0.0, supervisor.thrift.port=6628, topology.bolt.wait.strategy=org.apache.storm.policy.WaitStrategyProgressive, pacemaker.thread.timeout=10, storm.meta.serialization.delegate=org.apache.storm.serialization.GzipThriftSerializationDelegate, dev.zookeeper.path=/tmp/dev-storm-zookeeper, topology.skip.missing.kryo.registrations=false, drpc.invocations.threads=64, storm.zookeeper.session.timeout=20000, storm.metricstore.rocksdb.metadata_string_cache_capacity=4000, storm.workers.artifacts.dir=workers-artifacts, topology.component.resources.onheap.memory.mb=128.0, storm.log4j2.conf.dir=log4j2, storm.cluster.mode=distributed, ui.childopts=-Xmx768m, task.refresh.poll.secs=10, supervisor.childopts=-Xmx256m, task.credentials.poll.secs=30, storm.health.check.timeout.ms=5000, storm.blobstore.replication.factor=3, worker.profiler.command=flight.bash, storm.messaging.netty.buffer.low.watermark=8388608}
2023-12-26 22:42:46.705 o.a.s.d.w.Worker main [INFO] Worker e293af35-df7a-40df-9a19-3ba411ce1bfc for storm FirstStormClusterTopology-1-1703630456 on 02c58f36-6bc5-4837-95d5-a8f61f0d7d68:6700  has finished loading
2023-12-26 22:42:46.708 o.a.s.d.w.WorkerState Netty-server-localhost-6700-worker-1 [INFO] Sending BackPressure status to new client. BPStatus: {worker=e293af35-df7a-40df-9a19-3ba411ce1bfc, bpStatusId=1, bpTasks=[], nonBpTasks=[1, 4, 7]}
2023-12-26 22:42:46.899 o.a.s.m.n.Client client-worker-1 [ERROR] connection attempt 3 to Netty-Client-storm02/192.168.0.7:6700 failed: org.apache.storm.shade.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: storm02/192.168.0.7:6700
2023-12-26 22:42:47.049 o.a.s.m.n.Client client-worker-1 [ERROR] connection attempt 4 to Netty-Client-storm02/192.168.0.7:6700 failed: org.apache.storm.shade.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: storm02/192.168.0.7:6700
2023-12-26 22:42:48.781 o.a.s.m.n.Client client-worker-1 [ERROR] connection attempt 5 to Netty-Client-storm02/192.168.0.7:6700 failed: org.apache.storm.shade.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: storm02/192.168.0.7:6700
2023-12-26 22:42:48.951 o.a.s.m.n.Client client-worker-1 [ERROR] connection attempt 6 to Netty-Client-storm02/192.168.0.7:6700 failed: org.apache.storm.shade.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: storm02/192.168.0.7:6700
2023-12-26 22:42:49.253 o.a.s.m.n.Client client-worker-1 [ERROR] connection attempt 7 to Netty-Client-storm02/192.168.0.7:6700 failed: org.apache.storm.shade.io.netty.channel.AbstractChannel$AnnotatedConnectException: Connection refused: storm02/192.168.0.7:6700
2023-12-26 22:42:50.839 o.a.s.d.w.WorkerState refresh-active-timer [INFO] All connections are ready for worker 02c58f36-6bc5-4837-95d5-a8f61f0d7d68:6700 with id e293af35-df7a-40df-9a19-3ba411ce1bfc
2023-12-26 22:42:51.019 o.a.s.e.b.BoltExecutor Thread-18-FirstBolt-executor[1, 1] [INFO] Preparing bolt FirstBolt:[1]
2023-12-26 22:42:51.057 o.a.s.e.b.BoltExecutor Thread-15-__system-executor[-1, -1] [INFO] Preparing bolt __system:[-1]
2023-12-26 22:42:51.053 o.a.s.e.b.BoltExecutor Thread-16-FirstBolt-executor[4, 4] [INFO] Preparing bolt FirstBolt:[4]
2023-12-26 22:42:51.012 o.a.s.e.b.BoltExecutor Thread-17-__acker-executor[7, 7] [INFO] Preparing bolt __acker:[7]
2023-12-26 22:42:51.823 o.a.s.e.b.BoltExecutor Thread-18-FirstBolt-executor[1, 1] [INFO] Prepared bolt FirstBolt:[1]
2023-12-26 22:42:51.944 o.a.s.e.b.BoltExecutor Thread-16-FirstBolt-executor[4, 4] [INFO] Prepared bolt FirstBolt:[4]
2023-12-26 22:42:51.919 o.a.s.e.b.BoltExecutor Thread-17-__acker-executor[7, 7] [INFO] Prepared bolt __acker:[7]
2023-12-26 22:42:56.408 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [INFO] storm.cgroup.hierarchy.dir is not set or does not exist. checking storm.oci.cgroup.root
2023-12-26 22:42:56.408 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [INFO] storm.oci.cgroup.root is not set or does not exist
2023-12-26 22:42:56.409 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [WARN] CGroupCpuStat is disabled
2023-12-26 22:42:56.410 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [INFO] storm.cgroup.hierarchy.dir is not set or does not exist. checking storm.oci.cgroup.root
2023-12-26 22:42:56.410 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [INFO] storm.oci.cgroup.root is not set or does not exist
2023-12-26 22:42:56.410 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [WARN] CGroupMemoryLimit is disabled
2023-12-26 22:42:56.412 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [INFO] storm.cgroup.hierarchy.dir is not set or does not exist. checking storm.oci.cgroup.root
2023-12-26 22:42:56.412 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [INFO] storm.oci.cgroup.root is not set or does not exist
2023-12-26 22:42:56.412 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [WARN] CGroupCpuGuaranteeByCfsQuota is disabled
2023-12-26 22:42:56.413 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [INFO] storm.cgroup.hierarchy.dir is not set or does not exist. checking storm.oci.cgroup.root
2023-12-26 22:42:56.413 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [INFO] storm.oci.cgroup.root is not set or does not exist
2023-12-26 22:42:56.414 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [WARN] CGroupMemoryUsage is disabled
2023-12-26 22:42:56.415 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [INFO] storm.cgroup.hierarchy.dir is not set or does not exist. checking storm.oci.cgroup.root
2023-12-26 22:42:56.415 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [INFO] storm.oci.cgroup.root is not set or does not exist
2023-12-26 22:42:56.415 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [WARN] CGroupCpu is disabled
2023-12-26 22:42:56.420 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [INFO] storm.cgroup.hierarchy.dir is not set or does not exist. checking storm.oci.cgroup.root
2023-12-26 22:42:56.424 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [INFO] storm.oci.cgroup.root is not set or does not exist
2023-12-26 22:42:56.425 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [WARN] CGroupCpuGuarantee is disabled
2023-12-26 22:42:56.425 o.a.s.e.b.BoltExecutor Thread-15-__system-executor[-1, -1] [INFO] Prepared bolt __system:[-1]
2023-12-26 22:42:56.639 o.a.s.d.w.WorkerState Netty-server-localhost-6700-worker-1 [INFO] Sending BackPressure status to new client. BPStatus: {worker=e293af35-df7a-40df-9a19-3ba411ce1bfc, bpStatusId=4, bpTasks=[], nonBpTasks=[1, 4, 7]}
2023-12-26 22:42:59.873 o.a.s.u.Utils ShutdownHook-sleepKill-3s [INFO] Halting after 3 seconds
2023-12-26 22:42:59.873 o.a.s.d.w.Worker ShutdownHook-shutdownFunc [INFO] Shutting down worker FirstStormClusterTopology-1-1703630456 02c58f36-6bc5-4837-95d5-a8f61f0d7d68 6700
2023-12-26 22:42:59.873 o.a.s.m.n.Client ShutdownHook-shutdownFunc [INFO] closing Netty Client Netty-Client-storm03/192.168.0.8:6700
2023-12-26 22:42:59.873 o.a.s.m.n.Client ShutdownHook-shutdownFunc [INFO] waiting up to 600000 ms to send 0 pending messages to Netty-Client-storm03/192.168.0.8:6700
2023-12-26 22:42:59.878 o.a.s.m.n.Client ShutdownHook-shutdownFunc [INFO] closing Netty Client Netty-Client-storm02/192.168.0.7:6700
2023-12-26 22:42:59.878 o.a.s.m.n.Client ShutdownHook-shutdownFunc [INFO] waiting up to 600000 ms to send 0 pending messages to Netty-Client-storm02/192.168.0.7:6700
2023-12-26 22:42:59.878 o.a.s.d.w.Worker ShutdownHook-shutdownFunc [INFO] Terminating messaging context
2023-12-26 22:42:59.878 o.a.s.d.w.Worker ShutdownHook-shutdownFunc [INFO] Shutting down executors
2023-12-26 22:42:59.878 o.a.s.e.ExecutorShutdown ShutdownHook-shutdownFunc [INFO] Shutting down executor __system:[-1, -1]
2023-12-26 22:42:59.878 o.a.s.u.Utils Thread-15-__system-executor[-1, -1] [INFO] Async loop interrupted!
2023-12-26 22:42:59.881 o.a.s.e.ExecutorShutdown ShutdownHook-shutdownFunc [INFO] Shut down executor __system:[-1, -1]
2023-12-26 22:42:59.881 o.a.s.e.ExecutorShutdown ShutdownHook-shutdownFunc [INFO] Shutting down executor FirstBolt:[4, 4]
2023-12-26 22:42:59.881 o.a.s.u.Utils Thread-16-FirstBolt-executor[4, 4] [INFO] Async loop interrupted!
2023-12-26 22:42:59.881 o.a.s.e.ExecutorShutdown ShutdownHook-shutdownFunc [INFO] Shut down executor FirstBolt:[4, 4]
2023-12-26 22:42:59.882 o.a.s.e.ExecutorShutdown ShutdownHook-shutdownFunc [INFO] Shutting down executor __acker:[7, 7]
2023-12-26 22:42:59.882 o.a.s.u.Utils Thread-17-__acker-executor[7, 7] [INFO] Async loop interrupted!
2023-12-26 22:42:59.883 o.a.s.d.Acker ShutdownHook-shutdownFunc [INFO] Acker: cleanup successfully
2023-12-26 22:42:59.883 o.a.s.e.ExecutorShutdown ShutdownHook-shutdownFunc [INFO] Shut down executor __acker:[7, 7]
2023-12-26 22:42:59.883 o.a.s.e.ExecutorShutdown ShutdownHook-shutdownFunc [INFO] Shutting down executor FirstBolt:[1, 1]
2023-12-26 22:42:59.883 o.a.s.u.Utils Thread-18-FirstBolt-executor[1, 1] [INFO] Async loop interrupted!
2023-12-26 22:42:59.884 o.a.s.e.ExecutorShutdown ShutdownHook-shutdownFunc [INFO] Shut down executor FirstBolt:[1, 1]
2023-12-26 22:42:59.884 o.a.s.d.w.Worker ShutdownHook-shutdownFunc [INFO] Shut down executors
2023-12-26 22:42:59.884 o.a.s.d.w.Worker ShutdownHook-shutdownFunc [INFO] Shutting down transfer thread
2023-12-26 22:42:59.884 o.a.s.u.Utils Worker-Transfer [INFO] Async loop interrupted!
2023-12-26 22:42:59.890 o.a.s.d.w.Worker ShutdownHook-shutdownFunc [INFO] Shut down transfer thread
2023-12-26 22:43:02.102 o.a.s.d.w.WorkerState ShutdownHook-shutdownFunc [INFO] Shutting down default resources
2023-12-26 22:43:02.102 o.a.s.d.w.WorkerState ShutdownHook-shutdownFunc [INFO] Shut down default resources
2023-12-26 22:43:02.102 o.a.s.d.w.Worker ShutdownHook-shutdownFunc [INFO] Trigger any worker shutdown hooks
2023-12-26 22:43:02.109 o.a.s.d.w.Worker ShutdownHook-shutdownFunc [INFO] Disconnecting from storm cluster state context
2023-12-26 22:43:02.112 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl Curator-Framework-0 [INFO] backgroundOperationsLoop exiting
2023-12-26 22:43:02.222 o.a.s.s.o.a.z.ZooKeeper ShutdownHook-shutdownFunc [INFO] Session: 0x1000066708f0001 closed
2023-12-26 22:43:02.223 o.a.s.s.o.a.z.ClientCnxn main-EventThread [INFO] EventThread shut down for session: 0x1000066708f0001
2023-12-26 22:43:02.223 o.a.s.d.w.Worker ShutdownHook-shutdownFunc [INFO] Shut down worker FirstStormClusterTopology-1-1703630456 02c58f36-6bc5-4837-95d5-a8f61f0d7d68 6700
2023-12-26 22:43:03.664 o.a.s.v.ConfigValidation main [INFO] Will use [class org.apache.storm.Config, class org.apache.storm.hdfs.spout.Configs] for validation
2023-12-26 22:43:03.705 o.a.s.d.w.LogConfigManager main [INFO] Started with log levels: {=INFO, STDERR=INFO, STDOUT=INFO, org.apache.storm.metric.LoggingMetricsConsumer=INFO}
2023-12-26 22:43:03.718 o.a.s.d.w.Worker main [INFO] Adding shutdown hook with kill in 3 secs
2023-12-26 22:43:03.722 o.a.s.d.w.Worker main [INFO] Launching worker for FirstStormClusterTopology-1-1703630456 on 02c58f36-6bc5-4837-95d5-a8f61f0d7d68:6700 with id 95ab2efa-614b-43bd-b6ba-a9328cb5dc97 and conf {storm.messaging.netty.min_wait_ms=100, topology.backpressure.wait.strategy=org.apache.storm.policy.WaitStrategyProgressive, storm.resource.isolation.plugin=org.apache.storm.container.cgroup.CgroupManager, storm.zookeeper.auth.user=null, storm.messaging.netty.buffer_size=5242880, storm.exhibitor.port=8080, topology.bolt.wait.progressive.level1.count=1, pacemaker.auth.method=NONE, storm.oci.cgroup.root=/sys/fs/cgroup, ui.filter=null, worker.profiler.enabled=false, executor.metrics.frequency.secs=60, supervisor.thrift.threads=16, ui.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, supervisor.supervisors.commands=[], supervisor.queue.size=128, logviewer.cleanup.age.mins=10080, topology.tuple.serializer=org.apache.storm.serialization.types.ListDelegateSerializer, storm.cgroup.memory.enforcement.enable=false, drpc.port=3772, supervisor.localizer.update.blob.interval.secs=30, topology.max.spout.pending=null, topology.transfer.buffer.size=1000, storm.oci.nscd.dir=/var/run/nscd, nimbus.worker.heartbeats.recovery.strategy.class=org.apache.storm.nimbus.TimeOutWorkerHeartbeatsRecoveryStrategy, worker.metrics={CGroupMemory=org.apache.storm.metrics2.cgroup.CGroupMemoryUsage, CGroupMemoryLimit=org.apache.storm.metrics2.cgroup.CGroupMemoryLimit, CGroupCpu=org.apache.storm.metrics2.cgroup.CGroupCpu, CGroupCpuGuarantee=org.apache.storm.metrics2.cgroup.CGroupCpuGuarantee, CGroupCpuGuaranteeByCfsQuota=org.apache.storm.metrics2.cgroup.CGroupCpuGuaranteeByCfsQuota, CGroupCpuStat=org.apache.storm.metrics2.cgroup.CGroupCpuStat}, logviewer.port=8000, worker.childopts=-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump, topology.component.cpu.pcore.percent=10.0, storm.daemon.metrics.reporter.plugins=[org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter], worker.max.timeout.secs=600, blacklist.scheduler.resume.time.secs=1800, drpc.childopts=-Xmx768m, nimbus.task.launch.secs=120, logviewer.childopts=-Xmx128m, topology.ras.acker.executors.per.worker=1, storm.supervisor.hard.memory.limit.overage.mb=2024, storm.zookeeper.servers=[zookeeper00, zookeeper01, zookeeper02], storm.messaging.transport=org.apache.storm.messaging.netty.Context, storm.messaging.netty.authentication=false, topology.localityaware.higher.bound=0.8, storm.cgroup.memory.limit.tolerance.margin.mb=0.0, storm.cgroup.hierarchy.name=storm, blacklist.scheduler.assume.supervisor.bad.based.on.bad.slot=true, storm.metricprocessor.class=org.apache.storm.metricstore.NimbusMetricProcessor, topology.kryo.factory=org.apache.storm.serialization.DefaultKryoFactory, nimbus.assignments.service.threads=10, worker.heap.memory.mb=768, storm.network.topography.plugin=org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping, supervisor.slots.ports=[6700, 6701, 6702, 6703], topology.stats.sample.rate=0.05, storm.local.dir=/tmp/storm-data, topology.backpressure.wait.park.microsec=100, topology.ras.constraint.max.state.search=10000, storm.oci.cgroup.parent=/storm, topology.testing.always.try.serialize=false, nimbus.assignments.service.thread.queue.size=100, storm.principal.tolocal=org.apache.storm.security.auth.DefaultPrincipalToLocal, java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib:/usr/lib64, nimbus.local.assignments.backend.class=org.apache.storm.assignments.InMemoryAssignmentBackend, worker.gc.childopts=, storm.group.mapping.service.cache.duration.secs=120, topology.multilang.serializer=org.apache.storm.multilang.JsonSerializer, drpc.request.timeout.secs=600, nimbus.blobstore.class=org.apache.storm.blobstore.LocalFsBlobStore, topology.state.synchronization.timeout.secs=60, topology.bolt.wait.progressive.level2.count=1000, topology.worker.shared.thread.pool.size=4, topology.executor.receive.buffer.size=32768, pacemaker.servers=[], supervisor.monitor.frequency.secs=3, storm.nimbus.retry.times=5, topology.transfer.batch.size=1, transactional.zookeeper.port=null, storm.auth.simple-white-list.users=[], topology.scheduler.strategy=org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy, storm.zookeeper.port=2181, storm.zookeeper.retry.intervalceiling.millis=30000, storm.cluster.state.store=org.apache.storm.cluster.ZKStateStorageFactory, nimbus.thrift.port=6627, blacklist.scheduler.tolerance.count=3, nimbus.thrift.threads=64, supervisor.supervisors=[], nimbus.seeds=[storm00, storm01], storm.cluster.metrics.consumer.publish.interval.secs=60, logviewer.filter.params=null, topology.min.replication.count=1, nimbus.blobstore.expiration.secs=600, storm.group.mapping.service=org.apache.storm.security.auth.ShellBasedGroupsMapping, storm.nimbus.retry.interval.millis=2000, topology.max.task.parallelism=null, topology.backpressure.wait.progressive.level2.count=1000, drpc.https.keystore.password=, resource.aware.scheduler.constraint.max.state.search=100000, supervisor.heartbeat.frequency.secs=5, nimbus.credential.renewers.freq.secs=600, storm.supervisor.medium.memory.grace.period.ms=30000, storm.thrift.transport=org.apache.storm.security.auth.SimpleTransportPlugin, storm.cgroup.hierarchy.dir=/cgroup/storm_resources, storm.zookeeper.auth.password=null, ui.port=8080, drpc.authorizer.acl.strict=false, topology.message.timeout.secs=30, topology.error.throttle.interval.secs=10, topology.backpressure.check.millis=50, drpc.https.keystore.type=JKS, supervisor.memory.capacity.mb=4096.0, storm.metricstore.class=org.apache.storm.metricstore.rocksdb.RocksDbStore, drpc.authorizer.acl.filename=drpc-auth-acl.yaml, topology.builtin.metrics.bucket.size.secs=60, topology.spout.wait.park.microsec=100, storm.local.mode.zmq=false, pacemaker.client.max.threads=2, ui.header.buffer.bytes=4096, topology.shellbolt.max.pending=100, topology.serialized.message.size.metrics=false, drpc.max_buffer_size=1048576, drpc.disable.http.binding=true, storm.codedistributor.class=org.apache.storm.codedistributor.LocalFileSystemCodeDistributor, worker.profiler.childopts=-XX:+UnlockCommercialFeatures -XX:+FlightRecorder, nimbus.supervisor.timeout.secs=60, storm.supervisor.cgroup.rootdir=storm, topology.worker.max.heap.size.mb=768.0, storm.zookeeper.root=/storm, topology.disable.loadaware.messaging=false, topology.ras.one.executor.per.worker=false, storm.supervisor.hard.memory.limit.multiplier=2.0, nimbus.topology.validator=org.apache.storm.nimbus.DefaultTopologyValidator, worker.heartbeat.frequency.secs=1, storm.messaging.netty.max_wait_ms=1000, topology.backpressure.wait.progressive.level1.count=1, topology.max.error.report.per.interval=5, nimbus.thrift.max_buffer_size=1048576, storm.metricstore.rocksdb.location=storm_rocks, storm.supervisor.low.memory.threshold.mb=1024, pacemaker.max.threads=50, ui.pagination=20, ui.disable.http.binding=true, supervisor.blobstore.download.max_retries=3, topology.enable.message.timeouts=true, logviewer.disable.http.binding=true, storm.messaging.netty.transfer.batch.size=262144, topology.spout.wait.progressive.level2.count=0, blacklist.scheduler.strategy=org.apache.storm.scheduler.blacklist.strategies.DefaultBlacklistStrategy, storm.metricstore.rocksdb.retention_hours=240, supervisor.run.worker.as.user=false, storm.messaging.netty.client_worker_threads=1, topology.tasks=null, supervisor.thrift.socket.timeout.ms=5000, storm.group.mapping.service.params=null, drpc.http.port=3774, transactional.zookeeper.root=/transactional, supervisor.blobstore.download.thread.count=5, logviewer.filter=null, pacemaker.kerberos.users=[], topology.spout.wait.strategy=org.apache.storm.policy.WaitStrategyProgressive, storm.blobstore.inputstream.buffer.size.bytes=65536, supervisor.worker.heartbeats.max.timeout.secs=600, supervisor.worker.timeout.secs=30, topology.worker.receiver.thread.count=1, logviewer.max.sum.worker.logs.size.mb=4096, topology.executor.overflow.limit=0, topology.batch.flush.interval.millis=1, nimbus.file.copy.expiration.secs=600, pacemaker.port=6699, topology.worker.logwriter.childopts=-Xmx64m, drpc.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, nimbus.topology.blobstore.deletion.delay.ms=300000, storm.blobstore.acl.validation.enabled=false, ui.filter.params=null, topology.workers=1, blacklist.scheduler.tolerance.time.secs=300, storm.supervisor.medium.memory.threshold.mb=1536, topology.environment=null, drpc.invocations.port=3773, storm.metricstore.rocksdb.create_if_missing=true, nimbus.cleanup.inbox.freq.secs=600, client.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, topology.fall.back.on.java.serialization=false, storm.nimbus.retry.intervalceiling.millis=60000, storm.nimbus.zookeeper.acls.fixup=true, logviewer.appender.name=A1, ui.users=null, pacemaker.childopts=-Xmx1024m, storm.messaging.netty.server_worker_threads=1, scheduler.display.resource=false, ui.actions.enabled=true, storm.thrift.socket.timeout.ms=600000, storm.topology.classpath.beginning.enabled=false, storm.zookeeper.connection.timeout=15000, topology.tick.tuple.freq.secs=null, nimbus.inbox.jar.expiration.secs=3600, topology.debug=false, storm.zookeeper.retry.interval=1000, storm.messaging.netty.buffer.high.watermark=16777216, storm.blobstore.dependency.jar.upload.chunk.size.bytes=1048576, worker.log.level.reset.poll.secs=30, storm.exhibitor.poll.uripath=/exhibitor/v1/cluster/list, storm.zookeeper.retry.times=5, nimbus.code.sync.freq.secs=120, topology.component.resources.offheap.memory.mb=0.0, topology.spout.wait.progressive.level1.count=0, topology.state.checkpoint.interval.ms=1000, topology.priority=29, supervisor.localizer.cleanup.interval.ms=30000, storm.health.check.dir=healthchecks, supervisor.cpu.capacity=400.0, topology.backpressure.wait.progressive.level3.sleep.millis=1, storm.cgroup.resources=[cpu, memory], storm.worker.min.cpu.pcore.percent=0.0, topology.classpath=null, storm.nimbus.zookeeper.acls.check=true, num.stat.buckets=20, topology.spout.wait.progressive.level3.sleep.millis=1, supervisor.localizer.cache.target.size.mb=10240, topology.worker.childopts=null, drpc.https.port=-1, topology.bolt.wait.park.microsec=100, topology.max.replication.wait.time.sec=60, storm.cgroup.cgexec.cmd=/bin/cgexec, topology.acker.executors=null, topology.bolt.wait.progressive.level3.sleep.millis=1, supervisor.worker.start.timeout.secs=120, supervisor.worker.shutdown.sleep.secs=3, logviewer.max.per.worker.logs.size.mb=2048, topology.trident.batch.emit.interval.millis=500, task.heartbeat.frequency.secs=3, supervisor.enable=true, supervisor.thrift.max_buffer_size=1048576, supervisor.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, topology.producer.batch.size=1, drpc.worker.threads=64, resource.aware.scheduler.priority.strategy=org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy, blacklist.scheduler.reporter=org.apache.storm.scheduler.blacklist.reporters.LogReporter, storm.messaging.netty.socket.backlog=500, storm.cgroup.inherit.cpuset.configs=false, nimbus.queue.size=100000, drpc.queue.size=128, ui.disable.spout.lag.monitoring=true, topology.eventlogger.executors=0, pacemaker.base.threads=10, nimbus.childopts=-Xmx1024m, topology.spout.recvq.skips=3, storm.resource.isolation.plugin.enable=false, nimbus.monitor.freq.secs=10, storm.supervisor.memory.limit.tolerance.margin.mb=128.0, storm.disable.symlinks=false, topology.localityaware.lower.bound=0.2, transactional.zookeeper.servers=null, nimbus.task.timeout.secs=30, logs.users=null, pacemaker.thrift.message.size.max=10485760, topology.ras.one.component.per.worker=false, ui.host=0.0.0.0, supervisor.thrift.port=6628, topology.bolt.wait.strategy=org.apache.storm.policy.WaitStrategyProgressive, pacemaker.thread.timeout=10, storm.meta.serialization.delegate=org.apache.storm.serialization.GzipThriftSerializationDelegate, dev.zookeeper.path=/tmp/dev-storm-zookeeper, topology.skip.missing.kryo.registrations=false, drpc.invocations.threads=64, storm.zookeeper.session.timeout=20000, storm.metricstore.rocksdb.metadata_string_cache_capacity=4000, storm.workers.artifacts.dir=workers-artifacts, topology.component.resources.onheap.memory.mb=128.0, storm.log4j2.conf.dir=log4j2, storm.cluster.mode=distributed, ui.childopts=-Xmx768m, task.refresh.poll.secs=10, supervisor.childopts=-Xmx256m, task.credentials.poll.secs=30, storm.health.check.timeout.ms=5000, storm.blobstore.replication.factor=3, worker.profiler.command=flight.bash, storm.messaging.netty.buffer.low.watermark=8388608}
2023-12-26 22:43:03.730 o.a.s.s.u.o.l.s.c.SysOutOverSLF4JInitialiser main [WARN] Your logging framework class org.apache.logging.slf4j.Log4jLogger is not known - if it needs access to the standard println methods on the console you will need to register it by calling registerLoggingSystemPackage
2023-12-26 22:43:03.733 o.a.s.s.u.o.l.s.c.SysOutOverSLF4J main [INFO] Replaced standard System.out and System.err PrintStreams with SLF4JPrintStreams
2023-12-26 22:43:03.734 o.a.s.s.u.o.l.s.c.SysOutOverSLF4J main [INFO] Redirected System.out and System.err to SLF4J for this context
2023-12-26 22:43:03.763 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:zookeeper.version=3.5.9-83df9301aa5c2a5d284a9940177808c01bc35cef, built on 01/06/2021 20:03 GMT
2023-12-26 22:43:03.763 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:host.name=storm04
2023-12-26 22:43:03.763 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.version=1.8.0_181
2023-12-26 22:43:03.763 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.vendor=Oracle Corporation
2023-12-26 22:43:03.763 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.home=/usr/java/jdk1.8.0_181-amd64/jre
2023-12-26 22:43:03.763 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.class.path=/opt/apache-storm-2.4.0/lib-worker/jakarta.xml.bind-api-2.3.2.jar:/opt/apache-storm-2.4.0/lib-worker/minlog-1.3.0.jar:/opt/apache-storm-2.4.0/lib-worker/slf4j-api-1.7.36.jar:/opt/apache-storm-2.4.0/lib-worker/metrics-graphite-3.2.6.jar:/opt/apache-storm-2.4.0/lib-worker/javax.annotation-api-1.3.2.jar:/opt/apache-storm-2.4.0/lib-worker/log4j-api-2.17.1.jar:/opt/apache-storm-2.4.0/lib-worker/kryo-3.0.3.jar:/opt/apache-storm-2.4.0/lib-worker/log4j-core-2.17.1.jar:/opt/apache-storm-2.4.0/lib-worker/objenesis-2.1.jar:/opt/apache-storm-2.4.0/lib-worker/log4j-slf4j-impl-2.17.1.jar:/opt/apache-storm-2.4.0/lib-worker/jakarta.activation-1.2.1.jar:/opt/apache-storm-2.4.0/lib-worker/log4j-over-slf4j-1.7.36.jar:/opt/apache-storm-2.4.0/lib-worker/jakarta.activation-api-1.2.1.jar:/opt/apache-storm-2.4.0/lib-worker/metrics-core-3.2.6.jar:/opt/apache-storm-2.4.0/lib-worker/metrics-jvm-3.2.6.jar:/opt/apache-storm-2.4.0/lib-worker/asm-5.0.3.jar:/opt/apache-storm-2.4.0/lib-worker/reflectasm-1.10.1.jar:/opt/apache-storm-2.4.0/lib-worker/storm-shaded-deps-2.4.0.jar:/opt/apache-storm-2.4.0/lib-worker/storm-client-2.4.0.jar:/opt/apache-storm-2.4.0/extlib/*:/opt/apache-storm-2.4.0/conf:/tmp/storm-data/supervisor/stormdist/FirstStormClusterTopology-1-1703630456/stormjar.jar
2023-12-26 22:43:03.764 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.library.path=/tmp/storm-data/supervisor/stormdist/FirstStormClusterTopology-1-1703630456/resources/Linux-amd64:/tmp/storm-data/supervisor/stormdist/FirstStormClusterTopology-1-1703630456/resources:/usr/local/lib:/opt/local/lib:/usr/lib:/usr/lib64
2023-12-26 22:43:03.764 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.io.tmpdir=/tmp/storm-data/workers/95ab2efa-614b-43bd-b6ba-a9328cb5dc97/tmp
2023-12-26 22:43:03.764 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:java.compiler=<NA>
2023-12-26 22:43:03.764 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.name=Linux
2023-12-26 22:43:03.764 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.arch=amd64
2023-12-26 22:43:03.764 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.version=3.10.0-862.el7.x86_64
2023-12-26 22:43:03.764 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:user.name=root
2023-12-26 22:43:03.764 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:user.home=/root
2023-12-26 22:43:03.764 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:user.dir=/tmp/storm-data/workers/95ab2efa-614b-43bd-b6ba-a9328cb5dc97
2023-12-26 22:43:03.764 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.memory.free=85MB
2023-12-26 22:43:03.764 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.memory.max=341MB
2023-12-26 22:43:03.764 o.a.s.s.o.a.z.ZooKeeper main [INFO] Client environment:os.memory.total=119MB
2023-12-26 22:43:03.765 o.a.s.s.o.a.c.u.Compatibility main [INFO] Using emulated InjectSessionExpiration
2023-12-26 22:43:03.780 o.a.s.z.ClientZookeeper main [INFO] Starting ZK Curator
2023-12-26 22:43:03.780 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Starting
2023-12-26 22:43:03.788 o.a.s.s.o.a.z.ZooKeeper main [INFO] Initiating client connection, connectString=zookeeper00:2181,zookeeper01:2181,zookeeper02:2181 sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@6e35bc3d
2023-12-26 22:43:03.790 o.a.s.s.o.a.z.c.X509Util main [INFO] Setting -D jdk.tls.rejectClientInitiatedRenegotiation=true to disable client-initiated TLS renegotiation
2023-12-26 22:43:03.793 o.a.s.s.o.a.z.ClientCnxnSocket main [INFO] jute.maxbuffer value is 4194304 Bytes
2023-12-26 22:43:03.796 o.a.s.s.o.a.z.ClientCnxn main [INFO] zookeeper.request.timeout value is 0. feature enabled=
2023-12-26 22:43:03.801 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Default schema
2023-12-26 22:43:03.801 o.a.s.s.o.a.z.ClientCnxn main-SendThread(zookeeper00:2181) [INFO] Opening socket connection to server zookeeper00/192.168.0.2:2181. Will not attempt to authenticate using SASL (unknown error)
2023-12-26 22:43:03.804 o.a.s.s.o.a.z.ClientCnxn main-SendThread(zookeeper00:2181) [INFO] Socket connection established, initiating session, client: /192.168.0.9:51316, server: zookeeper00/192.168.0.2:2181
2023-12-26 22:43:03.810 o.a.s.s.o.a.z.ClientCnxn main-SendThread(zookeeper00:2181) [INFO] Session establishment complete on server zookeeper00/192.168.0.2:2181, sessionid = 0x666f260005, negotiated timeout = 20000
2023-12-26 22:43:03.812 o.a.s.s.o.a.c.f.s.ConnectionStateManager main-EventThread [INFO] State change: CONNECTED
2023-12-26 22:43:03.818 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl Curator-Framework-0 [INFO] backgroundOperationsLoop exiting
2023-12-26 22:43:03.819 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {server.1=zookeeper01:2888:3888:participant, version=0, server.0=zookeeper00:2888:3888:participant, server.2=zookeeper02:2888:3888:participant}
2023-12-26 22:43:03.822 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [ERROR] Invalid config event received: {server.1=zookeeper01:2888:3888:participant, version=0, server.0=zookeeper00:2888:3888:participant, server.2=zookeeper02:2888:3888:participant}
2023-12-26 22:43:03.822 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {server.1=zookeeper01:2888:3888:participant, version=0, server.0=zookeeper00:2888:3888:participant, server.2=zookeeper02:2888:3888:participant}
2023-12-26 22:43:03.822 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [ERROR] Invalid config event received: {server.1=zookeeper01:2888:3888:participant, version=0, server.0=zookeeper00:2888:3888:participant, server.2=zookeeper02:2888:3888:participant}
2023-12-26 22:43:03.925 o.a.s.s.o.a.z.ZooKeeper main [INFO] Session: 0x666f260005 closed
2023-12-26 22:43:03.925 o.a.s.s.o.a.z.ClientCnxn main-EventThread [INFO] EventThread shut down for session: 0x666f260005
2023-12-26 22:43:03.927 o.a.s.z.ClientZookeeper main [INFO] Starting ZK Curator
2023-12-26 22:43:03.927 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Starting
2023-12-26 22:43:03.928 o.a.s.s.o.a.z.ZooKeeper main [INFO] Initiating client connection, connectString=zookeeper00:2181,zookeeper01:2181,zookeeper02:2181/storm sessionTimeout=20000 watcher=org.apache.storm.shade.org.apache.curator.ConnectionState@3bd418e4
2023-12-26 22:43:03.928 o.a.s.s.o.a.z.ClientCnxnSocket main [INFO] jute.maxbuffer value is 4194304 Bytes
2023-12-26 22:43:03.929 o.a.s.s.o.a.z.ClientCnxn main [INFO] zookeeper.request.timeout value is 0. feature enabled=
2023-12-26 22:43:03.930 o.a.s.s.o.a.c.f.i.CuratorFrameworkImpl main [INFO] Default schema
2023-12-26 22:43:03.931 o.a.s.s.o.a.z.ClientCnxn main-SendThread(zookeeper02:2181) [INFO] Opening socket connection to server zookeeper02/192.168.0.4:2181. Will not attempt to authenticate using SASL (unknown error)
2023-12-26 22:43:03.932 o.a.s.s.o.a.z.ClientCnxn main-SendThread(zookeeper02:2181) [INFO] Socket connection established, initiating session, client: /192.168.0.9:33026, server: zookeeper02/192.168.0.4:2181
2023-12-26 22:43:03.937 o.a.s.s.o.a.z.ClientCnxn main-SendThread(zookeeper02:2181) [INFO] Session establishment complete on server zookeeper02/192.168.0.4:2181, sessionid = 0x20000666f2a0001, negotiated timeout = 20000
2023-12-26 22:43:03.938 o.a.s.s.o.a.c.f.s.ConnectionStateManager main-EventThread [INFO] State change: CONNECTED
2023-12-26 22:43:03.942 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {server.1=zookeeper01:2888:3888:participant, version=0, server.0=zookeeper00:2888:3888:participant, server.2=zookeeper02:2888:3888:participant}
2023-12-26 22:43:03.942 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [ERROR] Invalid config event received: {server.1=zookeeper01:2888:3888:participant, version=0, server.0=zookeeper00:2888:3888:participant, server.2=zookeeper02:2888:3888:participant}
2023-12-26 22:43:03.942 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [INFO] New config event received: {server.1=zookeeper01:2888:3888:participant, version=0, server.0=zookeeper00:2888:3888:participant, server.2=zookeeper02:2888:3888:participant}
2023-12-26 22:43:03.942 o.a.s.s.o.a.c.f.i.EnsembleTracker main-EventThread [ERROR] Invalid config event received: {server.1=zookeeper01:2888:3888:participant, version=0, server.0=zookeeper00:2888:3888:participant, server.2=zookeeper02:2888:3888:participant}
2023-12-26 22:43:03.949 o.a.s.m.StormMetricRegistry main [INFO] Starting metrics reporters...
2023-12-26 22:43:03.951 o.a.s.s.a.ClientAuthUtils main [INFO] Got AutoCreds []
2023-12-26 22:43:03.955 o.a.s.m.TransportFactory main [INFO] Storm peer transport plugin:org.apache.storm.messaging.netty.Context
2023-12-26 22:43:04.051 o.a.s.d.w.WorkerState main [INFO] Registering IConnectionCallbacks for 02c58f36-6bc5-4837-95d5-a8f61f0d7d68:6700
2023-12-26 22:43:04.594 o.a.s.m.n.Server main [INFO] Create Netty Server Netty-server-localhost-6700, buffer_size: 5242880, maxWorkers: 1
2023-12-26 22:43:04.656 o.a.s.m.n.Client main [INFO] Creating Netty Client, connecting to storm03:6700, bufferSize: 5242880, lowWatermark: 8388608, highWatermark: 16777216
2023-12-26 22:43:04.660 o.a.s.m.n.Client main [INFO] Creating Netty Client, connecting to storm02:6700, bufferSize: 5242880, lowWatermark: 8388608, highWatermark: 16777216
2023-12-26 22:43:04.737 o.a.s.d.w.WorkerState Netty-server-localhost-6700-worker-1 [INFO] Sending BackPressure status to new client. BPStatus: {worker=95ab2efa-614b-43bd-b6ba-a9328cb5dc97, bpStatusId=1, bpTasks=[], nonBpTasks=[1, 4, 7]}
2023-12-26 22:43:04.804 o.a.s.e.Executor main [INFO] Loading executor tasks __system:[-1, -1]
2023-12-26 22:43:04.805 o.a.s.e.Executor main [INFO] Finished loading executor __system:[-1, -1]
2023-12-26 22:43:04.805 o.a.s.e.Executor main [INFO] Loading executor tasks FirstBolt:[4, 4]
2023-12-26 22:43:04.805 o.a.s.e.Executor main [INFO] Finished loading executor FirstBolt:[4, 4]
2023-12-26 22:43:04.805 o.a.s.e.Executor main [INFO] Loading executor tasks __acker:[7, 7]
2023-12-26 22:43:04.806 o.a.s.e.Executor main [INFO] Finished loading executor __acker:[7, 7]
2023-12-26 22:43:04.806 o.a.s.e.Executor main [INFO] Loading executor tasks FirstBolt:[1, 1]
2023-12-26 22:43:04.806 o.a.s.e.Executor main [INFO] Finished loading executor FirstBolt:[1, 1]
2023-12-26 22:43:04.809 o.a.s.d.w.Worker main [INFO] Flush Tuple generation disabled. producerBatchSize=1, xferBatchSize=1, flushIntervalMillis=1
2023-12-26 22:43:04.809 o.a.s.d.w.Worker main [INFO] BackPressure status change checking will be performed every 50 millis
2023-12-26 22:43:04.809 o.a.s.d.w.Worker main [INFO] Worker has topology config {storm.messaging.netty.min_wait_ms=100, topology.backpressure.wait.strategy=org.apache.storm.policy.WaitStrategyProgressive, topology.submitter.principal=, storm.resource.isolation.plugin=org.apache.storm.container.cgroup.CgroupManager, storm.zookeeper.auth.user=null, storm.messaging.netty.buffer_size=5242880, topology.name=FirstStormClusterTopology, storm.exhibitor.port=8080, topology.bolt.wait.progressive.level1.count=1, pacemaker.auth.method=NONE, storm.oci.cgroup.root=/sys/fs/cgroup, ui.filter=null, worker.profiler.enabled=false, executor.metrics.frequency.secs=60, storm.id=FirstStormClusterTopology-1-1703630456, supervisor.thrift.threads=16, ui.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, supervisor.supervisors.commands=[], supervisor.queue.size=128, logviewer.cleanup.age.mins=10080, topology.tuple.serializer=org.apache.storm.serialization.types.ListDelegateSerializer, storm.cgroup.memory.enforcement.enable=false, drpc.port=3772, supervisor.localizer.update.blob.interval.secs=30, topology.max.spout.pending=null, topology.transfer.buffer.size=1000, storm.oci.nscd.dir=/var/run/nscd, nimbus.worker.heartbeats.recovery.strategy.class=org.apache.storm.nimbus.TimeOutWorkerHeartbeatsRecoveryStrategy, worker.metrics={CGroupCpuStat=org.apache.storm.metrics2.cgroup.CGroupCpuStat, CGroupMemoryLimit=org.apache.storm.metrics2.cgroup.CGroupMemoryLimit, CGroupCpuGuaranteeByCfsQuota=org.apache.storm.metrics2.cgroup.CGroupCpuGuaranteeByCfsQuota, CGroupMemory=org.apache.storm.metrics2.cgroup.CGroupMemoryUsage, CGroupCpu=org.apache.storm.metrics2.cgroup.CGroupCpu, CGroupCpuGuarantee=org.apache.storm.metrics2.cgroup.CGroupCpuGuarantee}, logviewer.port=8000, worker.childopts=-Xmx%HEAP-MEM%m -XX:+PrintGCDetails -Xloggc:artifacts/gc.log -XX:+PrintGCDateStamps -XX:+PrintGCTimeStamps -XX:+UseGCLogFileRotation -XX:NumberOfGCLogFiles=10 -XX:GCLogFileSize=1M -XX:+HeapDumpOnOutOfMemoryError -XX:HeapDumpPath=artifacts/heapdump, topology.component.cpu.pcore.percent=10.0, storm.daemon.metrics.reporter.plugins=[org.apache.storm.daemon.metrics.reporters.JmxPreparableReporter], worker.max.timeout.secs=600, blacklist.scheduler.resume.time.secs=1800, drpc.childopts=-Xmx768m, nimbus.task.launch.secs=120, logviewer.childopts=-Xmx128m, topology.ras.acker.executors.per.worker=1, storm.supervisor.hard.memory.limit.overage.mb=2024, storm.zookeeper.servers=[zookeeper00, zookeeper01, zookeeper02], storm.messaging.transport=org.apache.storm.messaging.netty.Context, storm.messaging.netty.authentication=false, topology.localityaware.higher.bound=0.8, storm.cgroup.memory.limit.tolerance.margin.mb=0.0, storm.cgroup.hierarchy.name=storm, blacklist.scheduler.assume.supervisor.bad.based.on.bad.slot=true, storm.metricprocessor.class=org.apache.storm.metricstore.NimbusMetricProcessor, topology.kryo.factory=org.apache.storm.serialization.DefaultKryoFactory, nimbus.assignments.service.threads=10, worker.heap.memory.mb=768, storm.network.topography.plugin=org.apache.storm.networktopography.DefaultRackDNSToSwitchMapping, supervisor.slots.ports=[6700, 6701, 6702, 6703], topology.stats.sample.rate=0.05, storm.local.dir=/tmp/storm-data, topology.backpressure.wait.park.microsec=100, topology.ras.constraint.max.state.search=10000, storm.oci.cgroup.parent=/storm, topology.testing.always.try.serialize=false, nimbus.assignments.service.thread.queue.size=100, storm.principal.tolocal=org.apache.storm.security.auth.DefaultPrincipalToLocal, java.library.path=/usr/local/lib:/opt/local/lib:/usr/lib:/usr/lib64, nimbus.local.assignments.backend.class=org.apache.storm.assignments.InMemoryAssignmentBackend, worker.gc.childopts=, storm.group.mapping.service.cache.duration.secs=120, topology.multilang.serializer=org.apache.storm.multilang.JsonSerializer, topology.kryo.register={}, drpc.request.timeout.secs=600, nimbus.blobstore.class=org.apache.storm.blobstore.LocalFsBlobStore, topology.state.synchronization.timeout.secs=60, topology.bolt.wait.progressive.level2.count=1000, topology.kryo.decorators=[], topology.worker.shared.thread.pool.size=4, topology.submitter.user=root, topology.executor.receive.buffer.size=32768, pacemaker.servers=[], supervisor.monitor.frequency.secs=3, storm.nimbus.retry.times=5, topology.transfer.batch.size=1, transactional.zookeeper.port=null, storm.auth.simple-white-list.users=[], topology.scheduler.strategy=org.apache.storm.scheduler.resource.strategies.scheduling.DefaultResourceAwareStrategy, storm.zookeeper.port=2181, storm.zookeeper.retry.intervalceiling.millis=30000, storm.cluster.state.store=org.apache.storm.cluster.ZKStateStorageFactory, nimbus.thrift.port=6627, blacklist.scheduler.tolerance.count=3, nimbus.thrift.threads=64, supervisor.supervisors=[], nimbus.seeds=[storm00, storm01], storm.cluster.metrics.consumer.publish.interval.secs=60, logviewer.filter.params=null, topology.min.replication.count=1, nimbus.blobstore.expiration.secs=600, storm.group.mapping.service=org.apache.storm.security.auth.ShellBasedGroupsMapping, storm.nimbus.retry.interval.millis=2000, topology.max.task.parallelism=null, topology.backpressure.wait.progressive.level2.count=1000, drpc.https.keystore.password=, resource.aware.scheduler.constraint.max.state.search=100000, supervisor.heartbeat.frequency.secs=5, nimbus.credential.renewers.freq.secs=600, storm.supervisor.medium.memory.grace.period.ms=30000, storm.thrift.transport=org.apache.storm.security.auth.SimpleTransportPlugin, storm.cgroup.hierarchy.dir=/cgroup/storm_resources, storm.zookeeper.auth.password=null, ui.port=8080, drpc.authorizer.acl.strict=false, topology.message.timeout.secs=30, topology.error.throttle.interval.secs=10, topology.backpressure.check.millis=50, drpc.https.keystore.type=JKS, supervisor.memory.capacity.mb=4096.0, storm.metricstore.class=org.apache.storm.metricstore.rocksdb.RocksDbStore, drpc.authorizer.acl.filename=drpc-auth-acl.yaml, topology.builtin.metrics.bucket.size.secs=60, topology.spout.wait.park.microsec=100, storm.local.mode.zmq=false, pacemaker.client.max.threads=2, ui.header.buffer.bytes=4096, topology.shellbolt.max.pending=100, topology.serialized.message.size.metrics=false, drpc.max_buffer_size=1048576, drpc.disable.http.binding=true, storm.codedistributor.class=org.apache.storm.codedistributor.LocalFileSystemCodeDistributor, worker.profiler.childopts=-XX:+UnlockCommercialFeatures -XX:+FlightRecorder, nimbus.supervisor.timeout.secs=60, storm.supervisor.cgroup.rootdir=storm, topology.worker.max.heap.size.mb=768.0, storm.zookeeper.root=/storm, topology.disable.loadaware.messaging=false, topology.ras.one.executor.per.worker=false, storm.supervisor.hard.memory.limit.multiplier=2.0, nimbus.topology.validator=org.apache.storm.nimbus.DefaultTopologyValidator, worker.heartbeat.frequency.secs=1, storm.messaging.netty.max_wait_ms=1000, topology.backpressure.wait.progressive.level1.count=1, topology.max.error.report.per.interval=5, nimbus.thrift.max_buffer_size=1048576, storm.metricstore.rocksdb.location=storm_rocks, storm.supervisor.low.memory.threshold.mb=1024, pacemaker.max.threads=50, ui.pagination=20, ui.disable.http.binding=true, supervisor.blobstore.download.max_retries=3, topology.enable.message.timeouts=true, logviewer.disable.http.binding=true, storm.messaging.netty.transfer.batch.size=262144, topology.spout.wait.progressive.level2.count=0, blacklist.scheduler.strategy=org.apache.storm.scheduler.blacklist.strategies.DefaultBlacklistStrategy, storm.metricstore.rocksdb.retention_hours=240, supervisor.run.worker.as.user=false, storm.messaging.netty.client_worker_threads=1, topology.tasks=null, supervisor.thrift.socket.timeout.ms=5000, storm.group.mapping.service.params=null, drpc.http.port=3774, transactional.zookeeper.root=/transactional, supervisor.blobstore.download.thread.count=5, logviewer.filter=null, pacemaker.kerberos.users=[], topology.spout.wait.strategy=org.apache.storm.policy.WaitStrategyProgressive, storm.blobstore.inputstream.buffer.size.bytes=65536, supervisor.worker.heartbeats.max.timeout.secs=600, supervisor.worker.timeout.secs=30, topology.worker.receiver.thread.count=1, logviewer.max.sum.worker.logs.size.mb=4096, topology.executor.overflow.limit=0, topology.batch.flush.interval.millis=1, nimbus.file.copy.expiration.secs=600, pacemaker.port=6699, topology.worker.logwriter.childopts=-Xmx64m, drpc.http.creds.plugin=org.apache.storm.security.auth.DefaultHttpCredentialsPlugin, nimbus.topology.blobstore.deletion.delay.ms=300000, storm.blobstore.acl.validation.enabled=false, ui.filter.params=null, topology.workers=3, blacklist.scheduler.tolerance.time.secs=300, storm.supervisor.medium.memory.threshold.mb=1536, topology.environment=null, drpc.invocations.port=3773, storm.metricstore.rocksdb.create_if_missing=true, nimbus.cleanup.inbox.freq.secs=600, client.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, topology.fall.back.on.java.serialization=false, storm.nimbus.retry.intervalceiling.millis=60000, storm.nimbus.zookeeper.acls.fixup=true, logviewer.appender.name=A1, ui.users=null, pacemaker.childopts=-Xmx1024m, storm.messaging.netty.server_worker_threads=1, scheduler.display.resource=false, ui.actions.enabled=true, storm.thrift.socket.timeout.ms=600000, storm.topology.classpath.beginning.enabled=false, storm.zookeeper.connection.timeout=15000, topology.tick.tuple.freq.secs=null, nimbus.inbox.jar.expiration.secs=3600, topology.debug=false, storm.zookeeper.retry.interval=1000, storm.messaging.netty.buffer.high.watermark=16777216, storm.blobstore.dependency.jar.upload.chunk.size.bytes=1048576, worker.log.level.reset.poll.secs=30, storm.exhibitor.poll.uripath=/exhibitor/v1/cluster/list, storm.zookeeper.retry.times=5, nimbus.code.sync.freq.secs=120, topology.component.resources.offheap.memory.mb=0.0, topology.spout.wait.progressive.level1.count=0, topology.state.checkpoint.interval.ms=1000, topology.priority=29, supervisor.localizer.cleanup.interval.ms=30000, storm.health.check.dir=healthchecks, supervisor.cpu.capacity=400.0, topology.backpressure.wait.progressive.level3.sleep.millis=1, storm.cgroup.resources=[cpu, memory], storm.worker.min.cpu.pcore.percent=0.0, topology.classpath=null, storm.nimbus.zookeeper.acls.check=true, num.stat.buckets=20, topology.spout.wait.progressive.level3.sleep.millis=1, supervisor.localizer.cache.target.size.mb=10240, topology.worker.childopts=null, drpc.https.port=-1, topology.bolt.wait.park.microsec=100, topology.max.replication.wait.time.sec=60, storm.cgroup.cgexec.cmd=/bin/cgexec, topology.users=[null], topology.acker.executors=null, topology.bolt.wait.progressive.level3.sleep.millis=1, supervisor.worker.start.timeout.secs=120, supervisor.worker.shutdown.sleep.secs=3, logviewer.max.per.worker.logs.size.mb=2048, topology.trident.batch.emit.interval.millis=500, task.heartbeat.frequency.secs=3, supervisor.enable=true, supervisor.thrift.max_buffer_size=1048576, supervisor.blobstore.class=org.apache.storm.blobstore.NimbusBlobStore, topology.producer.batch.size=1, drpc.worker.threads=64, resource.aware.scheduler.priority.strategy=org.apache.storm.scheduler.resource.strategies.priority.DefaultSchedulingPriorityStrategy, blacklist.scheduler.reporter=org.apache.storm.scheduler.blacklist.reporters.LogReporter, storm.messaging.netty.socket.backlog=500, storm.cgroup.inherit.cpuset.configs=false, nimbus.queue.size=100000, drpc.queue.size=128, ui.disable.spout.lag.monitoring=true, topology.eventlogger.executors=0, pacemaker.base.threads=10, nimbus.childopts=-Xmx1024m, topology.spout.recvq.skips=3, storm.zookeeper.superACL=null, storm.resource.isolation.plugin.enable=false, nimbus.monitor.freq.secs=10, storm.supervisor.memory.limit.tolerance.margin.mb=128.0, storm.disable.symlinks=false, topology.localityaware.lower.bound=0.2, transactional.zookeeper.servers=null, nimbus.task.timeout.secs=30, logs.users=null, pacemaker.thrift.message.size.max=10485760, topology.ras.one.component.per.worker=false, ui.host=0.0.0.0, supervisor.thrift.port=6628, topology.bolt.wait.strategy=org.apache.storm.policy.WaitStrategyProgressive, pacemaker.thread.timeout=10, storm.meta.serialization.delegate=org.apache.storm.serialization.GzipThriftSerializationDelegate, dev.zookeeper.path=/tmp/dev-storm-zookeeper, topology.skip.missing.kryo.registrations=false, drpc.invocations.threads=64, storm.zookeeper.session.timeout=20000, storm.metricstore.rocksdb.metadata_string_cache_capacity=4000, storm.workers.artifacts.dir=workers-artifacts, topology.component.resources.onheap.memory.mb=128.0, storm.log4j2.conf.dir=log4j2, storm.cluster.mode=distributed, ui.childopts=-Xmx768m, task.refresh.poll.secs=10, supervisor.childopts=-Xmx256m, task.credentials.poll.secs=30, storm.health.check.timeout.ms=5000, storm.blobstore.replication.factor=3, worker.profiler.command=flight.bash, storm.messaging.netty.buffer.low.watermark=8388608}
2023-12-26 22:43:04.810 o.a.s.d.w.Worker main [INFO] Worker 95ab2efa-614b-43bd-b6ba-a9328cb5dc97 for storm FirstStormClusterTopology-1-1703630456 on 02c58f36-6bc5-4837-95d5-a8f61f0d7d68:6700  has finished loading
2023-12-26 22:43:04.956 o.a.s.d.w.WorkerState refresh-active-timer [INFO] All connections are ready for worker 02c58f36-6bc5-4837-95d5-a8f61f0d7d68:6700 with id 95ab2efa-614b-43bd-b6ba-a9328cb5dc97
2023-12-26 22:43:04.957 o.a.s.e.b.BoltExecutor Thread-15-__system-executor[-1, -1] [INFO] Preparing bolt __system:[-1]
2023-12-26 22:43:04.960 o.a.s.e.b.BoltExecutor Thread-16-FirstBolt-executor[4, 4] [INFO] Preparing bolt FirstBolt:[4]
2023-12-26 22:43:04.961 o.a.s.e.b.BoltExecutor Thread-17-__acker-executor[7, 7] [INFO] Preparing bolt __acker:[7]
2023-12-26 22:43:05.007 o.a.s.e.b.BoltExecutor Thread-16-FirstBolt-executor[4, 4] [INFO] Prepared bolt FirstBolt:[4]
2023-12-26 22:43:05.018 o.a.s.e.b.BoltExecutor Thread-18-FirstBolt-executor[1, 1] [INFO] Preparing bolt FirstBolt:[1]
2023-12-26 22:43:05.018 o.a.s.e.b.BoltExecutor Thread-18-FirstBolt-executor[1, 1] [INFO] Prepared bolt FirstBolt:[1]
2023-12-26 22:43:05.019 o.a.s.e.b.BoltExecutor Thread-17-__acker-executor[7, 7] [INFO] Prepared bolt __acker:[7]
2023-12-26 22:43:05.023 o.a.s.d.w.WorkerState Netty-server-localhost-6700-worker-1 [INFO] Sending BackPressure status to new client. BPStatus: {worker=95ab2efa-614b-43bd-b6ba-a9328cb5dc97, bpStatusId=4, bpTasks=[], nonBpTasks=[1, 4, 7]}
2023-12-26 22:43:05.026 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [INFO] storm.cgroup.hierarchy.dir is not set or does not exist. checking storm.oci.cgroup.root
2023-12-26 22:43:05.026 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [INFO] storm.oci.cgroup.root is not set or does not exist
2023-12-26 22:43:05.026 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [WARN] CGroupCpuStat is disabled
2023-12-26 22:43:05.028 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [INFO] storm.cgroup.hierarchy.dir is not set or does not exist. checking storm.oci.cgroup.root
2023-12-26 22:43:05.028 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [INFO] storm.oci.cgroup.root is not set or does not exist
2023-12-26 22:43:05.028 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [WARN] CGroupMemoryLimit is disabled
2023-12-26 22:43:05.029 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [INFO] storm.cgroup.hierarchy.dir is not set or does not exist. checking storm.oci.cgroup.root
2023-12-26 22:43:05.029 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [INFO] storm.oci.cgroup.root is not set or does not exist
2023-12-26 22:43:05.029 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [WARN] CGroupCpuGuaranteeByCfsQuota is disabled
2023-12-26 22:43:05.030 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [INFO] storm.cgroup.hierarchy.dir is not set or does not exist. checking storm.oci.cgroup.root
2023-12-26 22:43:05.030 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [INFO] storm.oci.cgroup.root is not set or does not exist
2023-12-26 22:43:05.030 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [WARN] CGroupMemoryUsage is disabled
2023-12-26 22:43:05.031 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [INFO] storm.cgroup.hierarchy.dir is not set or does not exist. checking storm.oci.cgroup.root
2023-12-26 22:43:05.031 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [INFO] storm.oci.cgroup.root is not set or does not exist
2023-12-26 22:43:05.031 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [WARN] CGroupCpu is disabled
2023-12-26 22:43:05.032 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [INFO] storm.cgroup.hierarchy.dir is not set or does not exist. checking storm.oci.cgroup.root
2023-12-26 22:43:05.032 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [INFO] storm.oci.cgroup.root is not set or does not exist
2023-12-26 22:43:05.034 o.a.s.m.c.CGroupMetricsBase Thread-15-__system-executor[-1, -1] [WARN] CGroupCpuGuarantee is disabled
2023-12-26 22:43:05.035 o.a.s.e.b.BoltExecutor Thread-15-__system-executor[-1, -1] [INFO] Prepared bolt __system:[-1]
